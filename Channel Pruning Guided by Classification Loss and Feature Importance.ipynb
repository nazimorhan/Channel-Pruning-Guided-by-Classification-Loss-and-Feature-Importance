{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Channel Pruning Guided by Classification Loss and Feature Importance.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazimorhan/Channel-Pruning-Guided-by-Classification-Loss-and-Feature-Importance/blob/master/Channel%20Pruning%20Guided%20by%20Classification%20Loss%20and%20Feature%20Importance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZD8-z3zW2Zz"
      },
      "source": [
        "# 1 Import Required Modules"
      ],
      "id": "RZD8-z3zW2Zz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f526f2f2",
        "outputId": "4c255368-d631-44f2-a17c-87c09f2c2e70"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np              \n",
        "import time                     \n",
        "import random                   \n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "id": "f526f2f2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXAeXYQmPyVO"
      },
      "source": [
        "# 2 Prepare Data\n",
        "\n",
        "We will use CIFAR-10 dataset in order to test CPLI method which can be read from [here](https://arxiv.org/pdf/2003.06757.pdf). In the original paper, batch size is mentioned as 256. So we will use this values as batch size. But firstly a function for creating batches for a certain batch_size will be defined. "
      ],
      "id": "UXAeXYQmPyVO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig0yz3kPQLB4"
      },
      "source": [
        "def create_batches(batchSize):\n",
        "  # Make required transformation which is necessary for the inputs to VGG19 network\n",
        "  # Further info can be accessed from https://pytorch.org/hub/pytorch_vision_vgg/ \n",
        "  TF = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  ])\n",
        "\n",
        "  trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=TF)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=TF)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize,\n",
        "                                          shuffle=False, num_workers=2)\n",
        "  return trainloader, testloader\n",
        "\n",
        "CIFAR10_classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "id": "ig0yz3kPQLB4",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RibBOJszZsjQ"
      },
      "source": [
        "## 2.1 Enable GPU\n",
        "\n",
        "From \"Edit -> Notebook Settings -> Hardware accelerator\" select GPU. With the following we will specify to PyTorch that we want to use the GPU."
      ],
      "id": "RibBOJszZsjQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj0eJQBJZv8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c1b59a1-be02-4a10-80da-b528c9e97aab"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda (GPU support) is available and enabled!\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print(\"Cuda (GPU support) is not available :(\")\n",
        "  device = torch.device(\"cpu\")"
      ],
      "id": "Yj0eJQBJZv8i",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda (GPU support) is available and enabled!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYTUTso7ai_E"
      },
      "source": [
        "# 3 Download, Finetune and Test Original Pretrained VGG19"
      ],
      "id": "bYTUTso7ai_E"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnOk7c2Ma-Yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2fc0f4-1c10-45e7-96c4-09450e463092"
      },
      "source": [
        "# Create an instance of original pretrained VGG19\n",
        "origVGG = torchvision.models.vgg19(pretrained=True)\n",
        "# Visualize the network.\n",
        "print(origVGG)"
      ],
      "id": "vnOk7c2Ma-Yk",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-5ycTV0bsjO"
      },
      "source": [
        "## 3.1 Finetune Pre-Trained VGG19 on CIFAR-10\n",
        "\n",
        "Since VGG19 is pretrained on ImageNet dataset, we have to finetune the network for CIFAR-10."
      ],
      "id": "l-5ycTV0bsjO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj2M_FPdpJ7p"
      },
      "source": [
        "# Freeze the layers by setting requires_grad parameter to False.\n",
        "newVGG = copy.deepcopy(origVGG)\n",
        "for param in newVGG.parameters():\n",
        "  param.requires_grad = False"
      ],
      "id": "Bj2M_FPdpJ7p",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvxEBc2iqw41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8df9421-8c33-4f18-a346-d266bd3a92b8"
      },
      "source": [
        "newVGG.classifier[6] = None\n",
        "newVGG.classifier[6] = nn.Linear(4096, 10)\n",
        "for i,layer in enumerate(newVGG.classifier):\n",
        "  if i in [0,3,6]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad=True\n",
        "for param in newVGG.parameters():\n",
        "  print(param.requires_grad)"
      ],
      "id": "zvxEBc2iqw41",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkCHIUkWqzFQ"
      },
      "source": [
        "Define a $\\textbf{train}$ function in order to train the network"
      ],
      "id": "JkCHIUkWqzFQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQxlCIC-sBUJ"
      },
      "source": [
        "def train(model, criterion, optimizer, epochs, dataloader, scheduler, verbose=True):\n",
        "  \"\"\"\n",
        "    Define the trainer function. We can use this for training any model.\n",
        "    The parameter names are self-explanatory.\n",
        "\n",
        "    Returns: the loss history.\n",
        "  \"\"\"\n",
        "  loss_history = [] \n",
        "  for epoch in range(epochs):\n",
        "    for i, data in enumerate(dataloader, 0):    \n",
        "      \n",
        "      # Our batch:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # zero the gradients as PyTorch accumulates them\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Obtain the scores\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = criterion(outputs.to(device), labels)\n",
        "\n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "\n",
        "      # Update the weights\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_history.append(loss.item())\n",
        "    \n",
        "    scheduler.step()\n",
        "    \n",
        "    if verbose: print(f'Epoch {epoch} / {epochs}: avg. loss of last 5 iterations {np.sum(loss_history[:-6:-1])/5}')\n",
        "\n",
        "  return loss_history"
      ],
      "id": "ZQxlCIC-sBUJ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bygF59c9uDZE"
      },
      "source": [
        "Create the learnable parameters and make those the parameter of SGD optimizer. Also create the instances of loss function and send the model to GPU."
      ],
      "id": "bygF59c9uDZE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnLs78vmuehd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacc87a2-0d6b-4456-a351-47a46c43ac33"
      },
      "source": [
        "def get_learnable_parameters(model):\n",
        "    params_to_update = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "    return params_to_update\n",
        "\n",
        "batch_finetune = 256\n",
        "trainloader, testloader = create_batches(batch_finetune)\n",
        "weight_decay = 0.0001\n",
        "parameters_to_update = get_learnable_parameters(newVGG)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(parameters_to_update, lr=0.1, momentum=0.9, weight_decay=weight_decay)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer,1)\n",
        "\n",
        "newVGG = newVGG.to(device)\n",
        "epochs = 10\n",
        "loss_history = train(newVGG, criterion, optimizer, epochs, trainloader, scheduler)"
      ],
      "id": "fnLs78vmuehd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 10: avg. loss of last 5 iterations 0.848323392868042\n",
            "Epoch 1 / 10: avg. loss of last 5 iterations 0.5005512177944184\n",
            "Epoch 2 / 10: avg. loss of last 5 iterations 0.3965842664241791\n",
            "Epoch 3 / 10: avg. loss of last 5 iterations 0.361676287651062\n",
            "Epoch 4 / 10: avg. loss of last 5 iterations 0.3926823943853378\n",
            "Epoch 5 / 10: avg. loss of last 5 iterations 0.38514016270637513\n",
            "Epoch 6 / 10: avg. loss of last 5 iterations 0.42957322001457215\n",
            "Epoch 7 / 10: avg. loss of last 5 iterations 0.4373959720134735\n",
            "Epoch 8 / 10: avg. loss of last 5 iterations 0.41702077984809877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYbnqITwnpPK"
      },
      "source": [
        "testiter = iter(testloader)\n",
        "data, label = next(testiter)\n",
        "output = newVGG(data.to(device))\n",
        "print(output.data)\n"
      ],
      "id": "SYbnqITwnpPK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKYXJShvy7j9"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = newVGG(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "id": "NKYXJShvy7j9",
      "execution_count": null,
      "outputs": []
    }
  ]
}